# -*- coding: utf-8 -*-
"""DL 1A.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1c0xjcrOnJ68Oiu5h1Ep_KpBezWZNZeoj
"""

from google.colab import drive
import os

# Mount Google Drive
drive.mount('/content/drive')

# Define the directory to save models
model_save_dir = '/content/drive/MyDrive/trained_cnn_models'
os.makedirs(model_save_dir, exist_ok=True)

print(f"Google Drive mounted and directory created at: {model_save_dir}")

from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix
import numpy as np

def evaluate_model_metrics(model, testloader, device):
    """
    Evaluates the model on the test set and returns standard classification metrics.
    """
    model.eval()
    all_labels = []
    all_predictions = []
    all_probs = []

    with torch.no_grad():
        for images, labels in testloader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            probs = F.softmax(outputs, dim=1)
            _, predicted = torch.max(outputs.data, 1)

            all_labels.extend(labels.cpu().numpy())
            all_predictions.extend(predicted.cpu().numpy())
            all_probs.extend(probs.cpu().numpy())

    accuracy = accuracy_score(all_labels, all_predictions)
    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_predictions, average='macro')
    conf_matrix = confusion_matrix(all_labels, all_predictions)

    print("\n--- Standard Classification Metrics ---")
    print(f"Accuracy: {accuracy:.4f}")
    print(f"Precision (Macro): {precision:.4f}")
    print(f"Recall (Macro): {recall:.4f}")
    print(f"F1-Score (Macro): {f1:.4f}")
    print("Confusion Matrix:\n", conf_matrix)

    return accuracy, precision, recall, f1, conf_matrix, np.array(all_probs), np.array(all_labels)

import torchvision.transforms as transforms

def get_advanced_preprocessing_transforms():
    """
    Defines advanced data preprocessing transformations for CIFAR-10.
    Includes RandomCrop and RandomHorizontalFlip.
    """
    print("\n--- MILESTONE: Defining Advanced Preprocessing Transforms ---")
    transform_train = transforms.Compose([
        transforms.RandomCrop(32, padding=4),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
    ])

    transform_test = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
    ])
    print("Advanced preprocessing transforms defined.")
    return transform_train, transform_test

import numpy as np
from PIL import Image, ImageEnhance, ImageFilter
import torchvision.transforms as transforms

def apply_gaussian_noise(image, mean=0., std=0.1):
    """Applies Gaussian noise to a PIL Image."""
    img_array = np.array(image)
    noise = np.random.normal(mean, std, img_array.shape)
    noisy_img_array = img_array + noise
    noisy_img_array = np.clip(noisy_img_array, 0, 255).astype(np.uint8)
    return Image.fromarray(noisy_img_array)

def apply_blur(image, radius=2):
    """Applies Gaussian blur to a PIL Image."""
    return image.filter(ImageFilter.GaussianBlur(radius))

def apply_brightness_change(image, factor=1.5):
    """Changes the brightness of a PIL Image."""
    enhancer = ImageEnhance.Brightness(image)
    return enhancer.enhance(factor)

def apply_contrast_change(image, factor=1.5):
    """Changes the contrast of a PIL Image."""
    enhancer = ImageEnhance.Contrast(image)
    return enhancer.enhance(factor)

def apply_corruption(dataset, corruption_type='gaussian_noise', severity=1):
    """
    Applies a specific corruption to a dataset.
    Severity levels can be mapped to parameters (e.g., std for noise, radius for blur).
    This is a simplified implementation; real-world corruptions have more nuanced severity.
    """
    corrupted_images = []
    print(f"Applying {corruption_type} with severity {severity}...")

    for img, label in dataset:
        pil_img = transforms.ToPILImage()(img) # Convert tensor to PIL Image

        if corruption_type == 'gaussian_noise':
            # Map severity to std (example mapping)
            std = {1: 0.05, 2: 0.1, 3: 0.15, 4: 0.2, 5: 0.25}.get(severity, 0.1)
            corrupted_img = apply_gaussian_noise(pil_img, std=std)
        elif corruption_type == 'gaussian_blur':
            # Map severity to radius (example mapping)
            radius = {1: 0.5, 2: 1, 3: 1.5, 4: 2, 5: 2.5}.get(severity, 1)
            corrupted_img = apply_blur(pil_img, radius=radius)
        elif corruption_type == 'brightness':
             # Map severity to factor (example mapping)
            factor = {1: 0.7, 2: 0.85, 3: 1.0, 4: 1.15, 5: 1.3}.get(severity, 1.0)
            corrupted_img = apply_brightness_change(pil_img, factor=factor)
        elif corruption_type == 'contrast':
            # Map severity to factor (example mapping)
            factor = {1: 0.7, 2: 0.85, 3: 1.0, 4: 1.15, 5: 1.3}.get(severity, 1.0)
            corrupted_img = apply_contrast_change(pil_img, factor=factor)
        # Add more corruption types as needed
        else:
            raise ValueError(f"Unsupported corruption type: {corruption_type}")

        # Convert PIL Image back to tensor and apply normalization
        corrupted_tensor = transforms.ToTensor()(corrupted_img)
        normalized_corrupted_tensor = transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))(corrupted_tensor)

        corrupted_images.append((normalized_corrupted_tensor, label))

    # Create a DataLoader for the corrupted dataset
    corrupted_dataset = torch.utils.data.TensorDataset(torch.stack([img for img, _ in corrupted_images]),
                                                     torch.tensor([label for _, label in corrupted_images]))
    corrupted_loader = torch.utils.data.DataLoader(corrupted_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)

    print(f"Finished applying {corruption_type}.")
    return corrupted_loader

import numpy as np
import matplotlib.pyplot as plt
import torch

def calculate_ece(probs, labels, n_bins=10):
    """
    Calculates the Expected Calibration Error (ECE).
    Args:
        probs (np.ndarray): Array of shape (n_samples, n_classes) with predicted probabilities.
        labels (np.ndarray): Array of shape (n_samples,) with true labels.
        n_bins (int): Number of bins to use for calibration.
    Returns:
        float: The calculated ECE.
    """
    if probs.shape[0] != labels.shape[0]:
        raise ValueError("Probabilities and labels must have the same number of samples.")

    # Get the predicted class and its confidence (max probability)
    confidences = np.max(probs, axis=1)
    predictions = np.argmax(probs, axis=1)

    # Calculate the accuracy for each sample
    accuracies = (predictions == labels).astype(float)

    ece = 0.0
    bin_boundaries = np.linspace(0, 1, n_bins + 1)

    for i in range(n_bins):
        # Identify samples within the current confidence bin
        bin_start = bin_boundaries[i]
        bin_end = bin_boundaries[i+1]

        if i == n_bins - 1:
            # Include the upper boundary in the last bin
            bin_indices = np.where((confidences >= bin_start) & (confidences <= bin_end))[0]
        else:
            bin_indices = np.where((confidences >= bin_start) & (confidences < bin_end))[0]

        if len(bin_indices) > 0:
            # Calculate the average confidence and accuracy for this bin
            bin_confidence = np.mean(confidences[bin_indices])
            bin_accuracy = np.mean(accuracies[bin_indices])

            # Accumulate the weighted difference
            ece += (len(bin_indices) / len(confidences)) * np.abs(bin_confidence - bin_accuracy)

    return ece

def plot_reliability_diagram(probs, labels, n_bins=10):
    """
    Plots a reliability diagram.
    Args:
        probs (np.ndarray): Array of shape (n_samples, n_classes) with predicted probabilities.
        labels (np.ndarray): Array of shape (n_samples,) with true labels.
        n_bins (int): Number of bins to use for calibration.
    """
    if probs.shape[0] != labels.shape[0]:
        raise ValueError("Probabilities and labels must have the same number of samples.")

    confidences = np.max(probs, axis=1)
    predictions = np.argmax(probs, axis=1)
    accuracies = (predictions == labels).astype(float)

    bin_boundaries = np.linspace(0, 1, n_bins + 1)
    bin_middles = (bin_boundaries[:-1] + bin_boundaries[1:]) / 2.0

    bin_confidences = []
    bin_accuracies = []
    bin_counts = []

    for i in range(n_bins):
        bin_start = bin_boundaries[i]
        bin_end = bin_boundaries[i+1]

        if i == n_bins - 1:
             bin_indices = np.where((confidences >= bin_start) & (confidences <= bin_end))[0]
        else:
             bin_indices = np.where((confidences >= bin_start) & (confidences < bin_end))[0]


        if len(bin_indices) > 0:
            bin_confidences.append(np.mean(confidences[bin_indices]))
            bin_accuracies.append(np.mean(accuracies[bin_indices]))
            bin_counts.append(len(bin_indices))
        else:
            # Append NaN or 0 for empty bins, depending on desired plot behavior
            bin_confidences.append(bin_middles[i]) # Use bin middle for x-axis
            bin_accuracies.append(np.nan) # No accuracy for empty bin
            bin_counts.append(0)


    plt.figure(figsize=(8, 8))
    plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Perfectly Calibrated')
    plt.plot(bin_confidences, bin_accuracies, marker='o', linestyle='-', label='Model')

    plt.xlabel("Confidence")
    plt.ylabel("Accuracy")
    plt.title("Reliability Diagram")
    plt.legend()
    plt.grid(True)
    plt.show()

    # Optional: print bin counts
    # print("Bin counts:", bin_counts)

import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import torchvision
import torchvision.transforms as transforms
import time
import sys
import matplotlib.pyplot as plt
import numpy as np

# Assuming these functions are defined in previous cells and accessible
# from .your_module import get_advanced_preprocessing_transforms, evaluate_model_metrics, calculate_ece, plot_reliability_diagram, apply_corruption

# --- 1. Data Handling ---
def load_and_preprocess_data(use_advanced_transforms=False):
    """Loads CIFAR-10, normalizes, and creates DataLoaders."""
    print("\n--- MILESTONE: Data Loading & Preprocessing ---")

    if use_advanced_transforms:
        transform_train, transform_test = get_advanced_preprocessing_transforms()
    else:
        # Transform to normalize data to [-1, 1] for Tanh/Sigmoid stability
        transform_train = transforms.Compose(
            [transforms.ToTensor(),
             transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])
        transform_test = transforms.Compose(
            [transforms.ToTensor(),
             transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])


    print("Downloading/Loading CIFAR-10 dataset...")
    # Set num_workers > 0 for faster data loading, pin_memory=True helps transfer to GPU
    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,
                                            download=True, transform=transform_train)
    trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,
                                              shuffle=True, num_workers=2, pin_memory=True)

    testset = torchvision.datasets.CIFAR10(root='./data', train=False,
                                           download=True, transform=transform_test)
    testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE,
                                             shuffle=False, num_workers=2, pin_memory=True)

    print("Dataset loaded and DataLoaders created.")
    print(f"Trainset size: {len(trainset)} images")
    print(f"Testset size: {len(testset)} images")
    print(f"Data will be processed on device: {DEVICE}")
    if DEVICE.type == "cpu":
        print("WARNING: No GPU detected. Training will be slow.")

    print("--- MILESTONE: Data Loading Complete ---")
    return trainloader, testloader, testset # Also return testset for corruption

# --- 3. Efficient Experiment Workflow ---
def run_experiment(model, optimizer, trainloader, testloader, testset, epochs):
    """
    Trains and evaluates a model, times it, and returns results.
    Stores loss and time per iteration/epoch for plotting.
    Includes robustness evaluation on corrupted data.
    """
    model.to(DEVICE)
    criterion = nn.CrossEntropyLoss()

    print(f"--- MILESTONE: Starting Training ({epochs} epochs on {DEVICE}) ---")
    start_time = time.time()

    # Lists to store loss and time for plotting
    iteration_losses = []
    elapsed_times_iter = []
    epoch_losses = []
    epoch_times = []
    total_elapsed_time = 0

    for epoch in range(epochs):
        model.train()
        running_loss = 0.0
        epoch_start_time = time.time()

        for i, data in enumerate(trainloader, 0):
            iteration_start_time = time.time()
            inputs, labels = data
            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)

            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()

            # Store loss and time per iteration
            iteration_duration = time.time() - iteration_start_time
            total_elapsed_time += iteration_duration
            iteration_losses.append(loss.item())
            elapsed_times_iter.append(total_elapsed_time)

            # Print loss and time every 100 iterations
            if (i + 1) % 100 == 0:
                print(f"  Epoch {epoch + 1}/{epochs}, Iteration {i + 1}/{len(trainloader)}, Loss: {loss.item():.4f}, Elapsed Time: {total_elapsed_time:.2f}s", flush=True)


        # Store loss and time per epoch
        epoch_duration = time.time() - epoch_start_time
        epoch_losses.append(running_loss / len(trainloader))
        epoch_times.append(time.time() - start_time)

        # Print progress per epoch
        print(f"Epoch {epoch + 1}/{epochs} complete. Avg Loss: {running_loss / len(trainloader):.3f}, Epoch Time: {epoch_duration:.2f}s, Elapsed Total Time: {time.time() - start_time:.2f}s", flush=True)


    end_time = time.time()
    duration = end_time - start_time
    print(f"--- MILESTONE: Training Finished in {duration:.2f} seconds ---", flush=True)

    # --- Evaluation ---
    print("--- MILESTONE: Starting Evaluation on Test Set ---")
    model.eval()
    correct = 0
    total = 0
    all_labels = []
    all_predictions = []
    all_probs = []
    with torch.no_grad():
        for data in testloader:
            images, labels = data
            images, labels = images.to(DEVICE), labels.to(DEVICE)

            outputs = model(images)
            probs = F.softmax(outputs, dim=1)
            _, predicted = torch.max(outputs.data, 1)

            all_labels.extend(labels.cpu().numpy())
            all_predictions.extend(predicted.cpu().numpy())
            all_probs.extend(probs.cpu().numpy())

            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    final_val_acc = 100 * correct / total
    print(f"--- MILESTONE: Evaluation Complete. Final Val. Accuracy: {final_val_acc:.2f}% ---", flush=True)

    # Calculate and print additional metrics
    accuracy, precision, recall, f1, conf_matrix, probs, labels = evaluate_model_metrics(model, testloader, DEVICE)
    ece = calculate_ece(probs, labels)
    print(f"Expected Calibration Error (ECE): {ece:.4f}")

    # Plot reliability diagram
    plot_reliability_diagram(probs, labels)

    # --- Robustness Evaluation ---
    print("\n--- MILESTONE: Starting Robustness Evaluation ---")
    corruption_types = ['gaussian_noise', 'gaussian_blur', 'brightness', 'contrast']
    robustness_results = {}

    for corr_type in corruption_types:
        # Evaluate on a single severity level for demonstration (severity 3)
        corrupted_testloader = apply_corruption(testset, corruption_type=corr_type, severity=3)
        corr_accuracy, _, _, _, _, _, _ = evaluate_model_metrics(model, corrupted_testloader, DEVICE)
        robustness_results[corr_type] = corr_accuracy
        print(f"  Accuracy on {corr_type} (Severity 3): {corr_accuracy:.4f}%")

    print("--- MILESTONE: Robustness Evaluation Complete ---")


    # Return loss and time lists for plotting, and evaluation metrics
    return final_val_acc, duration, iteration_losses, elapsed_times_iter, epoch_losses, epoch_times, accuracy, precision, recall, f1, conf_matrix, ece, robustness_results

import torch
import torch.nn as nn
import torch.nn.functional as F

# --- 2. Model Architecture (2-Conv, 2-FC) ---
class Net(nn.Module):
    def __init__(self, activation_fn='relu'):
        super().__init__()

        # Set the activation function based on the string name
        if activation_fn == 'relu':
            self.activation = F.relu
        elif activation_fn == 'tanh':
            self.activation = torch.tanh
        elif activation_fn == 'sigmoid':
            self.activation = torch.sigmoid
        else:
            raise ValueError("Unsupported activation function")

        self.activation_name = activation_fn

        # --- Conv Block 1 ---
        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding='same')
        self.pool = nn.MaxPool2d(2, 2)

        # --- Conv Block 2 ---
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding='same')

        # --- FC Block ---
        self.fc1 = nn.Linear(64 * 8 * 8, 64)
        self.fc2 = nn.Linear(64, 10)

    def forward(self, x):
        x = self.pool(self.activation(self.conv1(x)))
        x = self.pool(self.activation(self.conv2(x)))
        x = torch.flatten(x, 1)
        x = self.activation(self.fc1(x))
        x = self.fc2(x)
        return x

import torch.nn as nn
import torch.nn.functional as F

# --- 2. Advanced Model Architecture (4-Conv, 2-FC, BatchNorm) ---
class ComplexNet(nn.Module):
    def __init__(self, activation_fn='relu'):
        super().__init__()

        # We only support ReLU for this model as requested
        if activation_fn != 'relu':
            raise ValueError("This model is designed for ReLU activation.")
        self.activation = F.relu

        # --- Conv Block 1 ---
        # 3 input channels (RGB), 32 output channels
        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding='same')
        self.bn1 = nn.BatchNorm2d(32) # Batch Norm for Conv layers

        # --- Conv Block 2 ---
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding='same')
        self.bn2 = nn.BatchNorm2d(64)
        self.pool1 = nn.MaxPool2d(2, 2) # 32x32 -> 16x16

        # --- Conv Block 3 ---
        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding='same')
        self.bn3 = nn.BatchNorm2d(128)

        # --- Conv Block 4 ---
        self.conv4 = nn.Conv2d(128, 128, kernel_size=3, padding='same')
        self.bn4 = nn.BatchNorm2d(128)
        self.pool2 = nn.MaxPool2d(2, 2) # 16x16 -> 8x8

        # --- FC Block ---
        # After two 2x2 pools, a 32x32 image becomes 8x8.
        # So, 128 channels * 8 * 8 = 8192 features
        self.fc1 = nn.Linear(128 * 8 * 8, 256)
        self.bn_fc1 = nn.BatchNorm1d(256) # Batch Norm for FC layers

        self.fc2 = nn.Linear(256, 10) # 10 output classes

    def forward(self, x):
        # The standard pattern with BatchNorm is:
        # Conv -> BatchNorm -> Activation -> Pool

        # Block 1
        x = self.activation(self.bn1(self.conv1(x)))
        # Block 2
        x = self.pool1(self.activation(self.bn2(self.conv2(x))))
        # Block 3
        x = self.activation(self.bn3(self.conv3(x)))
        # Block 4
        x = self.pool2(self.activation(self.bn4(self.conv4(x))))

        # Flatten all dimensions except batch
        x = torch.flatten(x, 1)

        # FC Block
        # FC -> BatchNorm -> Activation
        x = self.activation(self.bn_fc1(self.fc1(x)))
        # Output Layer (no activation, CrossEntropyLoss will apply softmax)
        x = self.fc2(x)
        return x

import torch.nn as nn
import torch.nn.functional as F

# --- 2. Advanced Model Architecture (with Residual Blocks) ---
class ResidualNet(nn.Module):
    def __init__(self, activation_fn='relu'):
        super().__init__()

        if activation_fn != 'relu':
            raise ValueError("This model is designed for ReLU activation.")
        self.activation = F.relu

        # --- Initial Conv Layer ---
        # 3 input channels (RGB), 32 output channels
        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding='same')
        self.bn1 = nn.BatchNorm2d(32)

        # --- Residual Block 1 (32 -> 64 channels, 32x32 -> 16x16) ---
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding='same')
        self.bn2 = nn.BatchNorm2d(64)
        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, padding='same')
        self.bn3 = nn.BatchNorm2d(64)
        # 1x1 conv "shortcut" to match dimensions (32 -> 64 channels)
        self.shortcut1 = nn.Conv2d(32, 64, kernel_size=1, padding=0)
        self.pool1 = nn.MaxPool2d(2, 2) # 32x32 -> 16x16

        # --- Residual Block 2 (64 -> 128 channels, 16x16 -> 8x8) ---
        self.conv4 = nn.Conv2d(64, 128, kernel_size=3, padding='same')
        self.bn4 = nn.BatchNorm2d(128)
        self.conv5 = nn.Conv2d(128, 128, kernel_size=3, padding='same')
        self.bn5 = nn.BatchNorm2d(128)
        # 1x1 conv "shortcut" to match dimensions (64 -> 128 channels)
        self.shortcut2 = nn.Conv2d(64, 128, kernel_size=1, padding=0)
        self.pool2 = nn.MaxPool2d(2, 2) # 16x16 -> 8x8

        # --- FC Block ---
        # 128 channels * 8 * 8 = 8192 features
        self.fc1 = nn.Linear(128 * 8 * 8, 256)
        self.bn_fc1 = nn.BatchNorm1d(256)
        self.fc2 = nn.Linear(256, 10) # 10 output classes

    def forward(self, x):
        # --- Initial Conv ---
        x = self.activation(self.bn1(self.conv1(x)))

        # --- ResBlock 1 ---
        # Create the shortcut (identity) path, matching channels
        identity1 = self.shortcut1(x)
        # Main path
        out = self.activation(self.bn2(self.conv2(x)))
        out = self.bn3(self.conv3(out)) # No activation before adding
        # Add skip connection
        out += identity1
        out = self.activation(out) # Activation *after* adding
        x = self.pool1(out) # Pool at the end of the block

        # --- ResBlock 2 ---
        # Create the shortcut (identity) path
        identity2 = self.shortcut2(x)
        # Main path
        out = self.activation(self.bn4(self.conv4(x)))
        out = self.bn5(self.conv5(out)) # No activation before adding
        # Add skip connection
        out += identity2
        out = self.activation(out) # Activation *after* adding
        x = self.pool2(out) # Pool at the end of the block

        # --- FC Block ---
        x = torch.flatten(x, 1)
        x = self.activation(self.bn_fc1(self.fc1(x)))
        x = self.fc2(x)
        return x

import torch
import torch.optim as optim
import matplotlib.pyplot as plt
import numpy as np
import sys
import os

# --- Configuration ---
# With a GPU, 10-15 epochs is feasible.
NUM_EPOCHS = 20 # Set to 1 for testing
BATCH_SIZE = 32
# This line automatically detects and selects your GPU
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Define the directory to save models (ensure this is defined or imported)
# Assuming model_save_dir is defined in a previous cell
# from your_setup_file import model_save_dir

# --- 4. Main Experiment Runner ---
def main():
    print("--- MILESTONE: Script Start ---")
    print(f"PyTorch Version: {torch.__version__}")
    print(f"CUDA Available: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        print(f"CUDA Version: {torch.version.cuda}")
        print(f"GPU Name: {torch.cuda.get_device_name(0)}")

    trainloader, testloader, testset = load_and_preprocess_data(use_advanced_transforms=True) # Use advanced transforms here and get testset

    # Define all experiments
    experiments = {
        "1_Baseline_ReLU_SGD": {
            'activation': 'relu',
            'optimizer_fn': lambda p: optim.SGD(p, lr=0.01)
        },
        "2_Activ_Tanh_SGD": {
            'activation': 'tanh',
            'optimizer_fn': lambda p: optim.SGD(p, lr=0.01)
        },
        "3_Activ_Sigmoid_SGD": {
            'activation': 'sigmoid',
            'optimizer_fn': lambda p: optim.SGD(p, lr=0.01)
        },
        "4_Optim_ReLU_SGD_Momentum": {
            'activation': 'relu',
            'optimizer_fn': lambda p: optim.SGD(p, lr=0.01, momentum=0.9)
        },
        "5_Optim_ReLU_Adam": {
            'activation': 'relu',
            'optimizer_fn': lambda p: optim.Adam(p) # Uses default lr
        }
    }

    results = [] # To store (name, accuracy, time, precision, recall, f1, ece, robustness_results) tuples

    print("\n--- MILESTONE: Starting Main Experiment Loop ---")
    for name, config in experiments.items():
        print(f"\n=======================================================")
        print(f"RUNNING EXPERIMENT: {name}")
        print(f"=========================================================")

        # Build a fresh model every time
        print("Instantiating model...")
        model = Net(activation_fn=config['activation'])
        print(f"Model created with activation: {model.activation_name}")

        # Build the optimizer for this specific model
        optimizer = config['optimizer_fn'](model.parameters())
        print(f"Optimizer created: {optimizer.__class__.__name__}")

        # Run and time the experiment and get metrics
        val_acc, train_time, iteration_losses, elapsed_times_iter, epoch_losses, epoch_times, accuracy, precision, recall, f1, conf_matrix, ece, robustness_results = run_experiment(model, optimizer, trainloader, testloader, testset,
                                             epochs=NUM_EPOCHS)

        # Store results
        results.append((name, config['activation'], optimizer.__class__.__name__, train_time, val_acc, accuracy, precision, recall, f1, ece, robustness_results))
        print(f"--- MILESTONE: Experiment {name} Complete ---")
        print(f"Result: Val. Acc = {val_acc:.2f}%, Time = {train_time:.2f}s, Accuracy = {accuracy:.4f}, ECE = {ece:.4f}")


        # Plotting
        plt.figure(figsize=(12, 5))

        # Plot loss vs time
        plt.subplot(1, 2, 1)
        plt.plot(elapsed_times_iter, iteration_losses)
        plt.xlabel("Elapsed Time (s)")
        plt.ylabel("Training Loss (Iteration)")
        plt.title(f"{name}: Training Loss vs. Time")
        plt.grid(True)

        # Plot loss vs epochs
        plt.subplot(1, 2, 2)
        plt.plot(range(1, len(epoch_losses) + 1), epoch_losses) # Fixed plotting for epochs
        plt.xlabel("Epoch")
        plt.ylabel("Training Loss (Epoch Avg)")
        plt.title(f"{name}: Training Loss vs. Epoch")
        plt.grid(True)

        plt.tight_layout()
        plt.show()

        # --- Save Model and Info ---
        try:
            model_info = {
                'architecture': model.__class__.__name__,
                'activation': model.activation_name if hasattr(model, 'activation_name') else 'N/A',
                'optimizer': optimizer.__class__.__name__,
                'epochs_trained': NUM_EPOCHS,
                'batch_size': BATCH_SIZE,
                'final_val_accuracy': val_acc,
                'training_time_sec': train_time,
                'accuracy': accuracy,
                'precision': precision,
                'recall': recall,
                'f1_score': f1,
                'ece': ece,
                'robustness_results': robustness_results,
                'state_dict': model.state_dict() # Save the model's state dictionary
            }

            # Create a unique filename
            timestamp = int(time.time())
            filename = f"{name}_{timestamp}.pth"
            filepath = os.path.join(model_save_dir, filename)

            # Save the model state dictionary and info
            torch.save(model_info, filepath)
            print(f"Model and info saved to: {filepath}")

        except Exception as e:
            print(f"Error saving model {name}: {e}")


    # --- 5. Final Results Summary ---
    print("\n\n--- MILESTONE: FINAL RESULTS SUMMARY ---")
    print(f"--- (All experiments trained for {NUM_EPOCHS} Epochs on {DEVICE}) ---")
    print("=======================================================================================================================================================")
    print(f"{'Experiment Name':<30} | {'Activation':<10} | {'Optimizer':<15} | {'Time (sec)':<12} | {'Val. Accuracy (%)':<18} | {'Accuracy':<10} | {'Precision':<10} | {'Recall':<10} | {'F1-Score':<10} | {'ECE':<10} | {'Robustness (Avg Acc %)'}")
    print("-------------------------------------------------------------------------------------------------------------------------------------------------------")
    for res in results:
        name, act, opt, t, val_acc, accuracy, precision, recall, f1, ece, robustness_results = res
        # Calculate average robustness accuracy for the summary table
        avg_robustness_acc = np.mean(list(robustness_results.values())) * 100 if robustness_results else 0
        print(f"{name:<30} | {act:<10} | {opt:<15} | {t:<12.2f} | {val_acc:<18.2f} | {accuracy:<10.4f} | {precision:<10.4f} | {recall:<10.4f} | {f1:<10.4f} | {ece:<10.4f} | {avg_robustness_acc:<22.2f}")

    print("=======================================================================================================================================================")
    print("\nUse this table to write your final recommendation paragraph.")
    print("Focus your analysis on *relative* performance (e.g., 'Adam converged fastest' or 'Sigmoid trained slowest').")
    print("\n--- MILESTONE: Script End ---")

if __name__ == "__main__":
    main()

import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import torchvision
import torchvision.transforms as transforms
import time
import sys
import os
import numpy as np

# --- Configuration ---
# User requested 50 "iterations", interpreted as 50 epochs.
NUM_EPOCHS = 20 # Set to 1 for testing
BATCH_SIZE = 64
# This line automatically detects and selects your GPU
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Define the directory to save models (ensure this is defined or imported)
# Assuming model_save_dir is defined in a previous cell
# from your_setup_file import model_save_dir

# --- 4. Main Experiment Runner (Simplified) ---
def main():
    print("--- MILESTONE: Script Start (Advanced Model) ---")
    print(f"PyTorch Version: {torch.__version__}")
    print(f"CUDA Available: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        print(f"CUDA Version: {torch.version.cuda}")
        print(f"GPU Name: {torch.cuda.get_device_name(0)}")

    trainloader, testloader, testset = load_and_preprocess_data(use_advanced_transforms=True) # Use advanced transforms here and get testset

    # Define the single experiment
    experiment_name = "6_ComplexNet_ReLU_Adam_BN"

    print(f"\n=======================================================")
    print(f"RUNNING EXPERIMENT: {experiment_name}")
    print(f"=======================================================")

    # 1. Build the model
    print("Instantiating ComplexNet (4-Conv, 2-FC, BatchNorm)...")
    model = ComplexNet(activation_fn='relu')

    # 2. Build the optimizer
    optimizer = optim.Adam(model.parameters())
    print(f"Optimizer created: {optimizer.__class__.__name__}")

    # 3. Run and time the experiment
    val_acc, train_time, iteration_losses, elapsed_times_iter, epoch_losses, epoch_times, accuracy, precision, recall, f1, conf_matrix, ece, robustness_results = run_experiment(model, optimizer, trainloader, testloader, testset,
                                         epochs=NUM_EPOCHS)

    print(f"--- MILESTONE: Experiment {experiment_name} Complete ---")

    # --- Save Model and Info ---
    try:
        model_info = {
            'architecture': model.__class__.__name__,
            'activation': model.activation_name if hasattr(model, 'activation_name') else 'N/A',
            'optimizer': optimizer.__class__.__name__,
            'epochs_trained': NUM_EPOCHS,
            'batch_size': BATCH_SIZE,
            'final_val_accuracy': val_acc,
            'training_time_sec': train_time,
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1_score': f1,
            'ece': ece,
            'robustness_results': robustness_results,
            'state_dict': model.state_dict() # Save the model's state dictionary
        }

        # Create a unique filename
        timestamp = int(time.time())
        filename = f"{experiment_name}_{timestamp}.pth"
        filepath = os.path.join(model_save_dir, filename)

        # Save the model state dictionary and info
        torch.save(model_info, filepath)
        print(f"Model and info saved to: {filepath}")

    except Exception as e:
        print(f"Error saving model {experiment_name}: {e}")


    # --- 5. Final Results Summary ---
    print("\n\n--- MILESTONE: FINAL RESULTS SUMMARY ---")
    print(f"--- (Trained for {NUM_EPOCHS} Epochs on {DEVICE}) ---")
    print("=======================================================================================================================================================")
    print(f"{'Experiment Name':<30} | {'Activation':<10} | {'Optimizer':<15} | {'Time (sec)':<12} | {'Val. Accuracy (%)':<18} | {'Accuracy':<10} | {'Precision':<10} | {'Recall':<10} | {'F1-Score':<10} | {'ECE':<10} | {'Robustness (Avg Acc %)'}")
    print("-------------------------------------------------------------------------------------------------------------------------------------------------------")
    # Print results for the single experiment
    avg_robustness_acc = np.mean(list(robustness_results.values())) * 100 if robustness_results else 0
    print(f"{experiment_name:<30} | {'relu':<10} | {'Adam':<15} | {train_time:<12.2f} | {val_acc:<18.2f} | {accuracy:<10.4f} | {precision:<10.4f} | {recall:<10.4f} | {f1:<10.4f} | {ece:<10.4f} | {avg_robustness_acc:<22.2f}")
    print("=======================================================================================================================================================")
    print("\n--- MILESTONE: Script End ---")

if __name__ == "__main__":
    main()

import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import torchvision
import torchvision.transforms as transforms
import time
import sys
import os
import numpy as np

# --- Configuration ---
# User requested 50 "iterations", interpreted as 50 epochs.
NUM_EPOCHS = 20 # Set to 1 for testing
BATCH_SIZE = 64
# This line automatically detects and selects your GPU
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Define the directory to save models (ensure this is defined or imported)
# Assuming model_save_dir is defined in a previous cell
# from your_setup_file import model_save_dir


# --- 4. Main Experiment Runner (Simplified) ---
def main():
    print("--- MILESTONE: Script Start (Residual Model) ---")
    print(f"PyTorch Version: {torch.__version__}")
    print(f"CUDA Available: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        print(f"CUDA Version: {torch.version.cuda}")
        print(f"GPU Name: {torch.cuda.get_device_name(0)}")

    trainloader, testloader, testset = load_and_preprocess_data(use_advanced_transforms=True) # Use advanced transforms here and get testset

    # Define the single experiment
    experiment_name = "7_ResidualNet_ReLU_Adam_BN"

    print(f"\n=======================================================")
    print(f"RUNNING EXPERIMENT: {experiment_name}")
    print(f"=======================================================")

    # 1. Build the model
    print("Instantiating ResidualNet (5-Conv, 2-FC, BatchNorm, Skips)...")
    model = ResidualNet(activation_fn='relu')

    # 2. Build the optimizer
    optimizer = optim.Adam(model.parameters())
    print(f"Optimizer created: {optimizer.__class__.__name__}")

    # 3. Run and time the experiment
    val_acc, train_time, iteration_losses, elapsed_times_iter, epoch_losses, epoch_times, accuracy, precision, recall, f1, conf_matrix, ece, robustness_results = run_experiment(model, optimizer, trainloader, testloader, testset,
                                         epochs=NUM_EPOCHS)

    print(f"--- MILESTONE: Experiment {experiment_name} Complete ---")

    # --- Save Model and Info ---
    try:
        model_info = {
            'architecture': model.__class__.__name__,
            'activation': model.activation_name if hasattr(model, 'activation_name') else 'N/A',
            'optimizer': optimizer.__class__.__name__,
            'epochs_trained': NUM_EPOCHS,
            'batch_size': BATCH_SIZE,
            'final_val_accuracy': val_acc,
            'training_time_sec': train_time,
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1_score': f1,
            'ece': ece,
            'robustness_results': robustness_results,
            'state_dict': model.state_dict() # Save the model's state dictionary
        }

        # Create a unique filename
        timestamp = int(time.time())
        filename = f"{experiment_name}_{timestamp}.pth"
        filepath = os.path.join(model_save_dir, filename)

        # Save the model state dictionary and info
        torch.save(model_info, filepath)
        print(f"Model and info saved to: {filepath}")

    except Exception as e:
        print(f"Error saving model {experiment_name}: {e}")


    # --- 5. Final Results Summary ---
    print("\n\n--- MILESTONE: FINAL RESULTS SUMMARY ---")
    print(f"--- (Trained for {NUM_EPOCHS} Epochs on {DEVICE}) ---")
    print("=======================================================================================================================================================")
    print(f"{'Experiment Name':<30} | {'Activation':<10} | {'Optimizer':<15} | {'Time (sec)':<12} | {'Val. Accuracy (%)':<18} | {'Accuracy':<10} | {'Precision':<10} | {'Recall':<10} | {'F1-Score':<10} | {'ECE':<10} | {'Robustness (Avg Acc %)'}")
    print("-------------------------------------------------------------------------------------------------------------------------------------------------------")
    # Print results for the single experiment
    avg_robustness_acc = np.mean(list(robustness_results.values())) * 100 if robustness_results else 0
    print(f"{experiment_name:<30} | {'relu':<10} | {'Adam':<15} | {train_time:<12.2f} | {val_acc:<18.2f} | {accuracy:<10.4f} | {precision:<10.4f} | {recall:<10.4f} | {f1:<10.4f} | {ece:<10.4f} | {avg_robustness_acc:<22.2f}")
    print("=======================================================================================================================================================")
    print("\n--- MILESTONE: Script End ---")

if __name__ == "__main__":
    main()

